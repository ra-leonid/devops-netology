## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

### Ответ:
Получить список активных операций можно командой: 
```commandline
db.currentOp()
```
Т.к. нам известно, что команда висит более 3-х минут, то добавим фильтры (будем считать, что операция выполняется в базе "db1"):

```commandline
db.currentOp(
   {
     "active" : true,
     "secs_running" : { "$gt" : 180 },
     "ns" : /^db1\./
   }
)
```
В ответе команды ищем нужный id. и подставляем его в команду прерывания операции:
```commandline
db.killOp(777)
```

Для предотвращения долгого выполнения запросов, правильным вариантом будет найти причину их зависания, возможно не хватает каких либо индексов, либо наоборот их слишком много и нужно неиспользуемые удалить. Либо использовать быстрый вариант, потенциально долгие команды, можно принудительно ограничивать с помощью метода maxTimeMS:
Пример:
```commandline
db.collection.find({description: /August [0-9]+, 1969/}).maxTimeMS(50)
```

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

### Ответ:
Возможно, что Redis использует активный алгоритм удаления истекших ключей, и их в базе очень много. В 1 секунду истекает срок действия у ключей более чем 25% от общего количества.
В таком случае Redis может заблокироваться, чтобы получить процент ключей, срок действия которых уже истек.
Такой подход необходим, чтобы не использовать слишком много памяти для ключей, срок действия которых уже истек.

## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

### Ответ:
Это ошибка потери соединения с сервером, при выполнении запроса.
Сообщение “during query”, говорит о том, что запрос пытается вернуть большой объем строк (миллионы), и, предположу, что ему не хватает на это времени.
* В таком случае, предлагается увеличить значение параметра "net_read_timeout", с дефолтного значения 30 секунд, до 60 или больше.
* Если это результат выполнения нескольких запросов, то попробовать оптимизировать их и получать результат частями.
* Возможно поможет добавление индексов, для более быстрого получения нужных данных.

Для подтверждения теории, необходимо будет включить отладку выполнения запроса и проверить, сколько предпролагается данных к выборке, какие индексы задействуются.

## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

### Ответ:
Когда памяти не хватает, oom-killer может уничтожить процесс PostgreSQL. Система жертвует "плохими" процессами и спасает систему от аварийного завершения.

Самый простой вариант, решить железом, добавив ОЗУ. Либо попробовать освободить её от ненужных процессов.

Если по пунктам выше, все варианты исчерпаны, в силу вступает план "Б".

Далее, информация из [источника](https://habr.com/ru/company/southbridge/blog/464245/). Оставляю здесь, не столько для подробного ответа, как больше для себя, на будущее.

Когда заканчивается память, вызывается функция out_of_memory(). В ней есть функция select_bad_process(), которая получает оценку от функции badness(). Под раздачу попадет самый «плохой» процесс. Функция badness() выбирает процесс по определенным правилам. У процессов с большими значениями используемой памяти, больше шансов стать жертвами OOM Killer. Процессы, связанные с привилегированным пользователем, имеют более низкую оценку и меньше шансов на принудительное завершение.

1. Разбираемся не является ли избыточное потребление ОЗУ причиной утечки памяти. Если да, то разработке необходимо найти причину и устранить.
2. Поверяем и ограничиваем настройки параметров сервера PostgreSQL:
   1. shared_buffers - Задаёт объём памяти, который будет использовать сервер баз данных для буферов в разделяемой памяти. Разумным начальным значением shared_buffers будет 25% от объёма памяти, но не более 40%.
   2. huge_pages - Определяет, будут ли огромные страницы запрашиваться из основной области общей памяти. Со значением off большие страницы не будут запрашиваться.
   3. work_mem - Задаёт базовый максимальный объём памяти, который будет использоваться во внутренних операциях при обработке запросов (например, для сортировки или хеш-таблиц), прежде чем будут задействованы временные файлы на диске.
   4. hash_mem_multiplier - Используется для определения максимального объёма памяти, который может выделяться для операций с хешированием. Итоговый объём определяется произведением work_mem и hash_mem_multiplier. 
   5. maintenance_work_mem - Задаёт максимальный объём памяти для операций обслуживания БД, в частности VACUUM, CREATE INDEX и ALTER TABLE ADD FOREIGN KEY.
   6. autovacuum_work_mem - Задаёт максимальный объём памяти, который будет использовать каждый рабочий процесс автоочистки.
   7. logical_decoding_work_mem - Задаёт максимальный объём памяти, используемой для логического декодирования, после превышения которого некоторые декодированные изменения будут вымещаться на локальный диск. 
   8. max_stack_depth - Задаёт максимальную безопасную глубину стека для исполнителя. В идеале это значение должно равняться предельному размеру стека, ограниченному ядром (который устанавливается командой ulimit -s или аналогичной), за вычетом запаса примерно в мегабайт.