## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

### Ответ:
Получить список активных операций можно командой: 
```commandline
db.currentOp()
```
Т.к. нам известно, что команда висит более 3-х минут, то добавим фильтры (будем считать, что операция выполняется в базе "db1"):

```commandline
db.currentOp(
   {
     "active" : true,
     "secs_running" : { "$gt" : 180 },
     "ns" : /^db1\./
   }
)
```
В ответе команды ищем нужный id. и подставляем его в команду прерывания операции:
```commandline
db.killOp(777)
```

для предотвращения долгого выполнения запросов, правильным вариантом будет найти причину их зависания, возможно не хватает каких либо индексов, либо наоборот их слишком много и нужно неиспользуемые удалить. Либо использовать быстрый вариант, потенциально долгие команды, можно принудительно ограничивать с помощью метода maxTimeMS:
Пример:
```commandline
db.collection.find({description: /August [0-9]+, 1969/}).maxTimeMS(50)
```

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

### Ответ:
Возможно, что Redis использует активный алгоритм удаления истекших ключей, и их в базе очень много. В 1 секунду истекает срок действия у ключей более чем 25% от общего количества.
В таком случае Redis может заблокироваться, чтобы получить процент ключей, срок действия которых уже истек.
Такой подход необходим, чтобы не использовать слишком много памяти для ключей, срок действия которых уже истек.

## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

### Ответ:
Это ошибка потери соединения с сервером, при выполнении запроса.
Сообщение “during query”, говорит о том, что запрос пытается вернуть большой объем строк (миллионы), и, предположу, что ему не хватает на это времени.
* В таком случае, предлагается увеличить значение параметра "net_read_timeout", с дефолтного значения 30 секунд, до 60 или больше.
* Если это результат выполнения нескольких запросов, то попробовать оптимизировать их и получать результат частями.
* Возможно поможет добавление нужных индексов, для более быстрого получения нужных данных.

Для подтверждения теории, необходимо будет включить отладку выполнения запроса и проверить, сколько предпролагается данных к выборке.

## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

### Ответ:
Когда памяти не хватает, oom-killer может уничтожить процесс PostgreSQL. Система жертвует "плохими" процессами и спасает систему от аварийного завершения.

Самый простой вариант, решить железом, добавив ОЗУ. Либо попробовать освободить её от ненужных процессов.

Если по пунктам выше, все варианты исчерпаны, в силу вступает план "Б".

Далее, информация из [источника](https://habr.com/ru/company/southbridge/blog/464245/). Оставляю здесь, не столько для подробного ответа, как больше для себя, на будущее.

Когда заканчивается память, вызывается функция out_of_memory(). В ней есть функция select_bad_process(), которая получает оценку от функции badness(). Под раздачу попадет самый «плохой» процесс. Функция badness() выбирает процесс по определенным правилам. У процессов с большими значениями используемой памяти, больше шансов стать жертвами OOM Killer. Процессы, связанные с привилегированным пользователем, имеют более низкую оценку и меньше шансов на принудительное завершение.
Чтобы снизить вероятность завершения нужного процесса, можно:
* Запускать их под рутом
* Снизить шанс его завершения, с помощью установки параметра ядра "oom_score_adj" для нашего процесса, в большое отрицательное значение
Узнаём pid процесса:
```commandline
postgres=# SELECT pg_backend_pid();
pg_backend_pid 
----------------
    3813
(1 row)
```

Снижаем шансы его завершения
Командой:
```commandline
sudo echo -1000 > /proc/3813/oom_score_adj
```

Либо в настройках СУБД:
```commandline
[Service]
OOMScoreAdjust=-1000
```

Либо можем совсем отключить OOM-Killer (настоятельно не рекомендуется) командой:
```commandline
sudo -s sysctl -w vm.oom-kill = 0
```

Включить его обратно, можно командой:
```commandline
sudo -s sysctl -w vm.oom-kill = 1
```

Результат этой команды сохранится не навсегда, а только до первой перезагрузки. Если нужно больше постоянства, добавьте эту строку в файл /etc/sysctl.conf:
```commandline
echo vm.oom-kill = 1 >>/etc/sysctl.conf
```

Еще один способ включения и отключения — написать переменную panic_on_oom. Значение всегда можно проверить в /proc.
```commandline
cat /proc/sys/vm/panic_on_oom
```

Если установить значение 0, то когда закончится память, kernel panic не будет.
```commandline
echo 0 > /proc/sys/vm/panic_on_oom
```
Если установить значение 1, то когда закончится память, случится kernel panic.

Также, можно ограничить резервирование ядром памяти для процессов. За это отвечает переменная vm.overcommit_memory.

Для нее можно указывать следующие значения:
* 0: ядро само решает, стоит ли резервировать слишком много памяти. Это значение по умолчанию в большинстве версий Linux.
* 1: ядро всегда будет резервировать лишнюю память. Это рискованно, ведь память может закончиться, потому что, скорее всего, однажды процессы затребуют положенное.
* 2: ядро не будет резервировать больше памяти, чем указано в параметре overcommit_ratio.

В параметре overcommit_ratio указывается процент памяти, для которого допустимо избыточное резервирование. Если для него нет места, память не выделяется, в резервировании будет отказано. **Это самый безопасный вариант, рекомендованный для PostgreSQL**. 

На OOM-Killer влияет еще один элемент — возможность подкачки, которой управляет переменная cat /proc/sys/vm/swappiness. Эти значения указывают ядру, как обрабатывать подкачку страниц. Чем больше значение, тем меньше вероятности, что OOM завершит процесс, но из-за операций ввода-вывода это негативно сказывается на базе данных. И наоборот — чем меньше значение, тем выше вероятность вмешательства OOM-Killer, но и производительность базы данных тоже выше. Значение по умолчанию 60, но если вся база данных помещается в память, лучше установить значение 1.